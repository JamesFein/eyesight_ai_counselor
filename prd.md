# 两阶段搜索系统改造 PRD

## 1. 项目背景与目标

### 1.1 改造目标

将现有的 `query.py` 单阶段检索系统改造为两阶段搜索架构，实现更精准的问答和完整的来源追溯。

### 1.2 核心价值

- **提高准确度**：通过问题分解和多维度检索，覆盖用户问题的各个方面
- **精确溯源**：每个论点都能追溯到权威文档的具体段落和来源
- **结构化输出**：小型报告格式，先结论后论据，便于快速理解

---

## 2. 核心需求

| 需求项       | 规格说明                                                              |
| ------------ | --------------------------------------------------------------------- |
| 子检索形式   | **肯定句**（非问句，与文本块更接近，提高检索命中率）                  |
| 子检索数量   | 第一阶段最多 5 个，第二阶段最多 5 个追加                              |
| 执行方式     | 先并行执行第一阶段，根据判断决定是否追加第二阶段                      |
| 第二阶段触发 | 由 LLM 扮演严谨且擅长批判性思维的验光师角色判断，大多数情况一阶段足够 |
| 输出结构     | TL;DR → 完整结论 → 论据（含原文段落+来源文件名）                      |
| 性能目标     | 流式输出首字 < 5 秒                                                   |

---

## 3. 系统架构设计

### 3.1 整体流程

```
用户输入问题
    ↓
[问题分解Agent]
    → 生成最多5个子检索肯定句
    ↓ (并行执行)
[混合检索] BM25 + 语义检索
    → 每个子检索获取相关文本块
    ↓ (并行执行)
[相关性判断Agent]
    → 从文本块中提取相关段落
    → 标注来源文件名
    → 生成子答案
    ↓
[充分性判断Agent]
    → 根据“原问题+子答案+子答案的相关段落和段落来源文件名”判断是否需要第二阶段
    → 如需要，生成追加子检索
    ↓
(条件执行) [第二阶段检索]
    → 执行追加的子检索
    ↓
[答案生成Agent]
    → 流式输出结构化答案
    → 先TL;DR，再完整结论，最后论据
```

### 3.2 四个核心 Agent

#### Agent 1: 问题分解 Agent

- **模型**：gpt-4.1（这个模型不仅要快，也要有相当的智能性，它的任务涉及到批判性思考）
- **职责**：将用户问题分解为 1-5 个子检索肯定句
- **输出结构**：子检索 ID + 肯定句 + 聚焦点
- **关键要求**：
  - 使用肯定句，不用问句
  - 覆盖多个维度（定义、原理、适应症、禁忌症、效果、注意事项等）
  - 使用专业术语，考虑同义词

#### Agent 2: 相关性判断 Agent

- **模型**：gpt-4.1（这个模型不仅要快，也要有相当的智能性,它的任务涉及到批判性思考）
- **职责**：判断检索到的文本块相关性，提取可用段落。注意，最终的目的是筛选出和子检索相关的文本块
- **输出结构**：子检索 ID + 相关段落提取列表 + 子答案 + 置信度 + 缺失方面
- **关键要求**：
  - 提取原文段落，不改写
  - 标注来源文件名
  - 评估置信度（high/medium/low）
  - 识别缺失的知识点

#### Agent 3: 充分性判断 Agent

- **模型**：gpt-4.1（这个模型不仅要快，也要有相当的智能性，它的任务涉及到批判性思考）
- **职责**：判断第一阶段检索是否充分，是否需要第二阶段
- **输出结构**：是否充分 + 置信度 + 已覆盖方面 + 缺失关键方面 + 追加子检索（如需要）+ 判断理由
- **关键要求**：
  - 扮演严谨验光师角色
  - 大多数情况应判断一阶段足够（控制触发率 < 20%）
  - 只在确实缺少关键信息时才触发第二阶段
  - 追加子检索最多 2-3 条

#### Agent 4: 答案生成 Agent

- **模型**：gpt-4.1（高质量输出）
- **职责**：流式生成结构化小型报告
- **输出结构**：
  1. TL;DR（太长不看）
  2. 完整专业结论
  3. 论据与来源（子论点 + 支持段落原文 + 来源文档名）
- **关键要求**：
  - 结论优先输出
  - 每个论点必须有来源支持
  - 引用原文时保持原文表述
  - 使用通俗易懂的语言，但保持专业准确

---

## 4. 数据结构设计

### 4.1 子检索结构（SubQuery）

- 子检索 ID
- 子检索肯定句
- 聚焦点（focus）

### 4.2 相关段落提取结构（RelevantExtract）

- 来源文件名
- 提取的相关段落原文

### 4.3 子检索分析结构（SubQueryAnalysis）

- 子检索 ID
- 子检索肯定句
- 子答案
- 相关段落提取列表
- 置信度（high/medium/low）
- 缺失的知识点描述列表

### 4.4 搜索阶段状态（SearchStageState）

- 原始问题
- 第一阶段子检索列表
- 第一阶段分析结果列表
- 是否需要第二阶段
- 第二阶段追加子检索列表
- 第二阶段分析结果列表

---

## 5. 实现步骤

### 步骤 1: 定义数据结构

在 `query.py` 中新增 Pydantic 模型类，定义上述 4.1-4.4 的数据结构。

### 步骤 2: 创建 4 个 Agent 实例

在 TwoStageQueryService 类初始化时创建 4 个 Pydantic-AI Agent 实例，配置各自的模型和参数。

### 步骤 3: 创建提示词文件

在 `prompts/` 目录下创建 4 个提示词文件：

- `decomposition_system_prompt.txt` - 问题分解
- `relevance_judge_system_prompt.txt` - 相关性判断
- `sufficiency_judge_system_prompt.txt` - 充分性判断
- `answer_generation_system_prompt.txt` - 答案生成

### 步骤 4: 实现第一阶段流程

- 问题分解方法
- 并行子检索执行方法（复用现有的 hybrid_search）
- 并行相关性判断方法
- 第一阶段完整流程编排方法

### 步骤 5: 实现判断与第二阶段流程

- 充分性判断方法
- 第二阶段检索流程（条件执行）
- 结果合并方法

### 步骤 6: 实现答案生成流程

- 流式答案生成方法
- 主入口方法（串联所有流程）

### 步骤 7: 更新配置文件

在 `.env` 中新增各 Agent 的配置项：

- 各 Agent 的模型选择
- 各 Agent 的温度和 max_tokens 设置
- 两阶段搜索的限制参数

### 步骤 8: 更新交互式主函数

修改 `main()` 函数以支持流式输出展示。

---

## 6. 性能优化策略

### 6.1 时间分配目标

| 阶段             | 目标耗时   | 优化手段                          |
| ---------------- | ---------- | --------------------------------- |
| 问题分解         | ~1 秒      | 使用 gpt-4.1                      |
| 第一阶段并行检索 | ~1.5 秒    | asyncio.gather 并行所有子检索     |
| 第一阶段并行判断 | ~1.5 秒    | asyncio.gather 并行所有相关性判断 |
| 充分性判断       | ~0.5 秒    | 使用 gpt4.1                       |
| 答案生成启动     | 立即       | 流式输出                          |
| **首字延迟**     | **< 5 秒** | **总计约 4.5 秒**                 |

### 6.2 并行化策略

- 所有子检索完全并行（不串行）
- 每个子检索内部的 BM25 和语义检索也并行
- 所有相关性判断完全并行
- 第二阶段（如触发）也采用相同并行策略

---

## 7. 配置项说明

### 7.1 Agent 配置

每个 Agent 需要独立配置：

- 模型选择（默认 gpt-4.1）
- temperature（0.1-0.7）
- max_tokens（300-2000）

### 7.2 搜索配置

- MAX_SUB_QUERIES: 5（第一阶段最多子检索数）
- MAX_ADDITIONAL_QUERIES: 5（第二阶段最多追加数）
- BM25_TOP_K: 5（BM25 检索 top-k）
- SEMANTIC_TOP_K: 5（语义检索 top-k）
- BM25_THRESHOLD: 0.0（BM25 分数阈值）
- SEMANTIC_THRESHOLD: 0.5（语义相似度阈值）

---

## 8. 输出格式规范

### 8.1 报告结构

整体采用三段式结构：

**第一段：TL;DR（太长不看）**

- 1-2 句话高度概括核心答案
- 包含最关键的数据和结论

**第二段：完整结论**

- 2-4 句话的专业完整结论
- 包含背景、核心内容、关键数据、注意事项

**第三段：论据与来源**

- 分条列出 3-5 个支持论点
- 每个论点包含：
  - 论点标题
  - 论点说明
  - 引用来源（文档名）
  - 原文引用（引号标注）

### 8.2 引用格式规范

- 来源文档名使用书名号：《近视管理白皮书（2025）》
- 原文引用使用引号："原文内容..."
- 不改写原文，保持原始表述

---

## 9. 关键文件清单

| 文件路径                                      | 操作类型 | 说明                                           |
| --------------------------------------------- | -------- | ---------------------------------------------- |
| `query.py`                                    | 重构     | 新增 TwoStageQueryService 类，保留现有检索方法 |
| `prompts/`                                    | 新建目录 | 存放 4 个提示词文件                            |
| `prompts/decomposition_system_prompt.txt`     | 新建     | 问题分解提示词                                 |
| `prompts/relevance_judge_system_prompt.txt`   | 新建     | 相关性判断提示词                               |
| `prompts/sufficiency_judge_system_prompt.txt` | 新建     | 充分性判断提示词                               |
| `prompts/answer_generation_system_prompt.txt` | 新建     | 答案生成提示词                                 |
| `.env`                                        | 修改     | 新增 Agent 配置项和搜索配置项                  |

---

## 10. 风险与应对

| 风险                  | 影响                   | 应对措施                                     |
| --------------------- | ---------------------- | -------------------------------------------- |
| LLM 响应慢导致超 5 秒 | 用户体验下降           | 设置超时保护，降级为单次检索                 |
| 第二阶段触发过于频繁  | 响应时间变长，成本增加 | 优化充分性判断提示词，强调"大多数一阶段足够" |
| 相关段落提取不准确    | 来源溯源不精确         | 提示词强调"保留原文，不改写"                 |
| 子检索肯定句生成不当  | 检索效果差             | 提示词提供丰富示例，强调专业术语和同义词     |
| 并行请求导致 API 限流 | 请求失败               | 设置重试机制，考虑限制并发数                 |

---

## 11. 后续优化方向

### 11.1 简单问题快速路径

对于简单直接的问题，可跳过问题分解，直接单次检索+生成。

### 11.2 结果缓存

对于相同或相似问题，缓存最终结果以实现秒级响应。

### 11.3 批量嵌入优化

将多个子检索的文本嵌入请求合并为一次 API 调用。

### 11.4 监控指标

记录关键指标以持续优化：

- 首字节延迟
- 第二阶段触发率
- 各阶段耗时
- 答案满意度（需用户反馈）
